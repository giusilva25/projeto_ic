{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM3Fo1J+5kbETslaTDgm/g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####**TOKENIZAÇÃO DO TEXTO EM SENTENÇAS E CONTAGEM DE SENTENÇAS**"
      ],
      "metadata": {
        "id": "-guDusNtXhHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/Classificador/texto_natural/Graciliano.txt', 'r') as f:\n",
        "  texto = f.read()\n",
        "\n",
        "texto_limpo = re.sub(r'\\s+', ' ', texto)\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "sentencas = nltk.sent_tokenize(texto_limpo)\n",
        "\n",
        "num_sentencas = len(sentencas)\n",
        "\n",
        "for sentenca in sentencas:\n",
        "    print(sentenca)\n",
        "\n",
        "print(f\"Número total de sentenças: {num_sentencas}\")\n",
        "\n",
        "with open('/content/drive/MyDrive/Classificador/sentencas_natural.txt', 'w') as f:\n",
        "  for sentenca in sentencas:\n",
        "    f.write(sentenca + '\\n')\n",
        "\n",
        "print(\"'/content/drive/MyDrive/Classificador/sentencas_natural.txt\")"
      ],
      "metadata": {
        "id": "FdHNWfgpXgZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**EMBARALHAMENTO E ESTRATIFICAÇÃO**"
      ],
      "metadata": {
        "id": "uPDMbw-pcCMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from google.colab import drive\n",
        "\n",
        "def carregar_sentencas(file_path):\n",
        "    \"\"\"Loads sentences from a file, assuming one sentence per line.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        sentences = [line.strip() for line in file]\n",
        "    return sentences\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "texto_artificial = '/content/drive/MyDrive/Classificador/sentencas_artificial.txt'\n",
        "texto_natural = '/content/drive/MyDrive/Classificador/sentencas_natural.txt'\n",
        "\n",
        "artificial_train = carregar_sentencas(texto_artificial)\n",
        "natural_train = carregar_sentencas(texto_natural)\n",
        "\n",
        "print(f\"artificial: {len(artificial_train)}\")\n",
        "print(f\"natural: {len(natural_train)}\")\n",
        "\n",
        "all_sents = [(sent, \"artificial\") for sent in artificial_train]\n",
        "all_sents += [(sent, \"natural\") for sent in natural_train]\n",
        "\n",
        "print(f\"Dataset size = {len(all_sents)} sentences\")\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "values = [texto for (sent, texto) in all_sents]\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "strat_train_set = []\n",
        "strat_pretest_set = []\n",
        "\n",
        "for train_index, pretest_index in split.split(all_sents, values):\n",
        "    strat_train_set = [all_sents[index] for index in train_index]\n",
        "    strat_pretest_set = [all_sents[index] for index in pretest_index]\n",
        "\n",
        "train_data = [[sent] for sent, _ in strat_train_set]\n",
        "pretest_data = [[sent] for sent, _ in strat_pretest_set]\n",
        "\n",
        "train_df = pd.DataFrame(train_data, columns=['Sentenca'])\n",
        "pretest_df = pd.DataFrame(pretest_data, columns=['Sentenca'])\n",
        "\n",
        "train_df['Classe'] = [autor for _, autor in strat_train_set]\n",
        "pretest_df['Classe'] = [autor for _, autor in strat_pretest_set]\n",
        "\n",
        "print(\"DataFrame de Treinamento:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nDataFrame de Pré-Teste:\")\n",
        "print(pretest_df.head())\n",
        "\n",
        "train_df.to_csv('/content/drive/MyDrive/Classificador/treinamento.csv', index=False)\n",
        "pretest_df.to_csv('/content/drive/MyDrive/Classificador/preteste.csv', index=False)"
      ],
      "metadata": {
        "id": "zP_m2NHxcQKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**PORCENTAGEM DE DADOS NOS CONJUNTOS DE TREINAMENTO E TESTE**"
      ],
      "metadata": {
        "id": "i8-kFjELYNx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def cat_proportions(data, cat):\n",
        "    count = 0\n",
        "    for item in data:\n",
        "        if item[1] == cat:\n",
        "            count += 1\n",
        "    return float(count) / float(len(data))\n",
        "\n",
        "def read_data_from_file(file_path, category):\n",
        "    data = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            data.append((line.strip(), category))\n",
        "    return data\n",
        "\n",
        "artificial_file_path = '/content/drive/MyDrive/Classificador/sentencas_artificial.txt'\n",
        "natural_file_path = '/content/drive/MyDrive/Classificador/sentencas_natural.txt'\n",
        "\n",
        "artificial_data = read_data_from_file(artificial_file_path, \"texto_artificial\")\n",
        "natural_data = read_data_from_file(natural_file_path, \"texto_natural\")\n",
        "\n",
        "all_sents = [(sent, \"texto_artificial\") for sent in artificial_data]\n",
        "all_sents += [(sent, \"texto_natural\") for sent in natural_data]\n",
        "\n",
        "texts = [item[0] for item in all_sents]\n",
        "labels = [item[1] for item in all_sents]\n",
        "\n",
        "strat_train_set, strat_pretest_set = train_test_split(\n",
        "    list(zip(texts, labels)),\n",
        "    test_size=0.2,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "categories = [\"texto_artificial\", \"texto_natural\"]\n",
        "\n",
        "rows = []\n",
        "rows.append([\"Category\", \"Overall\", \"Stratified train\", \"Stratified pretest\"])\n",
        "\n",
        "for cat in categories:\n",
        "    rows.append([\n",
        "        cat,\n",
        "        f\"{cat_proportions(all_sents, cat):.6f}\",\n",
        "        f\"{cat_proportions(strat_train_set, cat):.6f}\",\n",
        "        f\"{cat_proportions(strat_pretest_set, cat):.6f}\"\n",
        "    ])\n",
        "def print_table(rows):\n",
        "    column_widths = [max(len(str(item)) for item in col) for col in zip(*rows)]\n",
        "\n",
        "    for row in rows:\n",
        "        print(\" | \".join(f\"{str(row[i]):<{column_widths[i]}}\" for i in range(len(row))))\n",
        "        print(\"-\" * (sum(column_widths) + 3 * (len(row) - 1)))\n",
        "\n",
        "print_table(rows)"
      ],
      "metadata": {
        "id": "ciHzXXHfXTg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**ESTATÍSTICAS SIMPLES**"
      ],
      "metadata": {
        "id": "Zvo-Qn9zXO3V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ymwNLazXJ-Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Classificador/preteste.csv')\n",
        "\n",
        "def calcular_estatisticas(sentencas):\n",
        "    num_chars = sum(len(sentence) for sentence in sentencas)\n",
        "    num_words = sum(len(sentence.split()) for sentence in sentencas)\n",
        "    num_sents = len(sentencas)\n",
        "    num_vocab = len(set(word.lower() for sentence in sentencas for word in sentence.split()))\n",
        "\n",
        "    media_caracteres_por_palavra = round(num_chars / num_words, 2) if num_words > 0 else 0\n",
        "    media_palavras_por_sentenca = round(num_words / num_sents, 2) if num_sents > 0 else 0\n",
        "    media_palavras_por_palavra_unica = round(num_words / num_vocab, 2) if num_vocab > 0 else 0\n",
        "\n",
        "    return media_caracteres_por_palavra, media_palavras_por_sentenca, media_palavras_por_palavra_unica\n",
        "\n",
        "df['media_caracteres_por_palavra'] = df['Sentenca'].apply(lambda x: calcular_estatisticas([x])[0])\n",
        "df['media_palavras_por_sentenca'] = df['Sentenca'].apply(lambda x: calcular_estatisticas([x])[1])\n",
        "df['media_palavras_por_palavra_unica'] = df['Sentenca'].apply(lambda x: calcular_estatisticas([x])[2])\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/Classificador/teste/preteste_com_estatisticas.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**ETIQUETAGEM**\n"
      ],
      "metadata": {
        "id": "QO0hp90QrAfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "input_csv = '/content/drive/MyDrive/Classificador/preteste.csv'\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "def extract_pos_features(sentenca):\n",
        "    doc = nlp(sentenca)\n",
        "    tag_freq = Counter(token.pos_ for token in doc)\n",
        "    possible_tags = ['DET', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'PRON', 'AUX']\n",
        "    features = {tag: tag_freq.get(tag, 0) for tag in possible_tags}\n",
        "    return features\n",
        "\n",
        "features_list = df['Sentenca'].apply(extract_pos_features)\n",
        "\n",
        "features_df = pd.DataFrame(features_list.tolist())\n",
        "features_df['Sentenca'] = df['Sentenca']\n",
        "features_df['Classe'] = df['Classe']\n",
        "\n",
        "columns = ['Sentenca', 'Classe'] + list(features_df.columns[:-2])\n",
        "features_df = features_df[columns]\n",
        "\n",
        "print(features_df.head())\n",
        "\n",
        "output_csv = '/content/drive/MyDrive/Classificador/etiquetagem_preteste.csv'\n",
        "features_df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f'salvo em: {output_csv}')\n"
      ],
      "metadata": {
        "id": "tIUJahtmflie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**CLASSIFICADOR BASEADO EM MEDIA DE CARACTERES POR PALAVRA, MEDIA DE PALAVRAS POR SENTENÇAS E MEDIA DE PALAVRAS POR PALAVRA ÚNICA**"
      ],
      "metadata": {
        "id": "VY6lq_8us1Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df_treinamento = pd.read_csv('/content/drive/MyDrive/Classificador/teste/treinamento_com_estatisticas.csv')\n",
        "\n",
        "df_teste = pd.read_csv('/content/drive/MyDrive/Classificador/teste/preteste_com_estatisticas.csv')\n",
        "\n",
        "X_train = df_treinamento[['media_caracteres_por_palavra', 'media_palavras_por_sentenca', 'media_palavras_por_palavra_unica']]\n",
        "y_train = df_treinamento['Classe']\n",
        "\n",
        "X_test = df_teste[['media_caracteres_por_palavra', 'media_palavras_por_sentenca', 'media_palavras_por_palavra_unica']]\n",
        "y_test = df_teste['Classe']\n",
        "\n",
        "model = MultinomialNB()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy * 100:.2f}%')\n",
        "\n",
        "print(\"classification_report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion_matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "g9xO7i2PtDik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**CLASSIFICADOR BASEADO EM FREQUÊNCIA DE TAGS**"
      ],
      "metadata": {
        "id": "QysrVmerte7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df_treinamento = pd.read_csv('/content/drive/MyDrive/Classificador/etiquetagem_treinamento.csv')\n",
        "\n",
        "df_teste = pd.read_csv('/content/drive/MyDrive/Classificador/etiquetagem_preteste.csv')\n",
        "\n",
        "X_train = df_treinamento[['DET', 'NOUN',\t'VERB',\t'ADV',\t'ADJ',\t'ADP',\t'PRON',\t'AUX']]\n",
        "y_train = df_treinamento['Classe']\n",
        "\n",
        "X_test = df_teste[['DET', 'NOUN',\t'VERB',\t'ADV',\t'ADJ',\t'ADP',\t'PRON',\t'AUX']]\n",
        "y_test = df_teste['Classe']\n",
        "\n",
        "model = MultinomialNB()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy * 100:.2f}%')\n",
        "\n",
        "print(\"classification_report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"confusion_matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "xfDcaUuQtbqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**CLASSIFICADOR BASEADO EM BAG OF WORDS**"
      ],
      "metadata": {
        "id": "aDqh8-dmtrQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "input_train_csv = '/content/drive/MyDrive/Classificador/treinamento.csv'\n",
        "input_test_csv = '/content/drive/MyDrive/Classificador/preteste.csv'\n",
        "df_train = pd.read_csv(input_train_csv)\n",
        "df_test = pd.read_csv(input_test_csv)\n",
        "\n",
        "print(\"Dados de treinamento:\")\n",
        "print(df_train.head())\n",
        "print(\"\\nDados de teste:\")\n",
        "print(df_test.head())\n",
        "\n",
        "sentences_train = df_train['Sentenca'].tolist()\n",
        "labels_train = df_train['Classe'].tolist()\n",
        "\n",
        "sentences_test = df_test['Sentenca'].tolist()\n",
        "labels_test = df_test['Classe'].tolist()\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words=None, max_features=10000)\n",
        "X_train = vectorizer.fit_transform(sentences_train)\n",
        "X_test = vectorizer.transform(sentences_test)\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, labels_train)\n",
        "\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(labels_test, y_pred)\n",
        "print(f'Acurácia: {accuracy:.4f}')\n",
        "\n",
        "print('classification_report:')\n",
        "print(classification_report(labels_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "XrIktuwTttLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**CLASSIFICADOR BASEADO EM TF-IDF**"
      ],
      "metadata": {
        "id": "x1i-6Hm2uHvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "input_train_csv = '/content/drive/MyDrive/Classificador/treinamento.csv'\n",
        "df_train = pd.read_csv(input_train_csv)\n",
        "\n",
        "input_test_csv = '/content/drive/MyDrive/Classificador/preteste.csv'\n",
        "df_test = pd.read_csv(input_test_csv)\n",
        "\n",
        "print(\"Dados de treinamento:\")\n",
        "print(df_train.head())\n",
        "print(\"\\nDados de teste:\")\n",
        "print(df_test.head())\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(df_train['Sentenca'])\n",
        "y_train = df_train['Classe']\n",
        "\n",
        "X_test_tfidf = vectorizer.transform(df_test['Sentenca'])\n",
        "y_test = df_test['Classe']\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
        "    'fit_prior': [True, False]\n",
        "    }\n",
        "\n",
        "grid_search = GridSearchCV(estimator=nb_model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
        "\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"grid_search.best_params:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_tfidf)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy:.4f}')\n",
        "\n",
        "print('classification_report:')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "p9OSbs5PuMRz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}